Models for en-fr machine translation comparisons

Link to dataset: https://www.kaggle.com/datasets/dhruvildave/en-fr-translation-dataset

Evaluation files: This folder contains the files pertaining to the human evaluations of the model
error analysis.xlsx contains the detailed error analysis of 100 annotated examples for types of input that were difficult for each model
Annotator guidelines contains the full guidelines emailed to the human evaluator
LLAMA-qlora-eval-100k.xlsx contains the human evaluations of the LLaMA model for 100k lines
LLAMA-qlora-eval.xlsx contains the human evaluations of the LLaMA model for 80k lines
mt5-eval.xlsx contains the human evaluations of the finetuned mt5 model for 200k lines
mt5-qlora-eval.xlsx contains the human evaluations of the mt5 model fine-tuned with QLoRA for 200k lines
mt5-prompt-tuning.xlsx contains the human evaluations of the prompt-tuned mt5 model for 200k lines

mt5 fine tuning 100k.ipynb contians the code for the fine-tuned mt5 model for 100k lines
mt5 fine tuning 200k.ipynb contains the code for the fine-tuned mt5 model for 200k lines
mt5 fine tuning Load.ipynb loads the fine-tuned mt5 model
mt5_QLoRA.ipynb contains the code for the mt5 model fine-tuned with QLoRA for 200k lines
mt5_QLoRA_load.ipynb loads the mt5 model fine-tuned with QLoRA

